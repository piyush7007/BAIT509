Q1 - Bagging is a special case of random forests under which case?
A1. when m=p, subset of predictors = equal full predictors

Q2 - What are the hyperparameters we can control for random forests?
A2 -  m, number of trees, number of predictors you subset

Q3 -  Suppose you have the following paired data of (x,y): (1,2), (1,5), (2,0). Which of the following are valid bootstrapped data sets? Why/why not?
        (1,0), (1,2), (1,5)
        (1,2), (2,0)
        (1,2), (1,2), (1,5)
A3 - 3rd is significant - (1,2), (1,2), (1,5)

Q4 - For each of the above valid bootstapped data sets, which observations are out-of-bag (OOB)?
A4 - (2,0)

Q5 - You make a random forest consisting of four trees. You obtain a new observation of predictors, and would like to predict the response. What would your prediction be in the following cases?
      a.Regression: your trees make the following four predictions: 1,1,3,3.
      b.Classification: your trees make the following four predictions: “A”, “A”, “B”, “C”.
A5(a) - 2 -> average of 1,1,3,3
A5(b) - "A"
